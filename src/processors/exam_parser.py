"""
Parser de Exames com Claude Haiku
Extrai, normaliza e deduplica resultados de exames
Economia estimada: ~66% vs Claude Sonnet
"""

import re
import json
import uuid
from typing import List, Dict, Any
from src.config import (
    CLAUDE_HAIKU_MODEL,
    CLAUDE_MAX_TOKENS,
    CLAUDE_TEMPERATURE,
    EXAM_NAME_SIMILARITY_THRESHOLD
)


def parse_exams_from_text(extracted_text: str, anthropic_client) -> List[Dict[str, Any]]:
    """
    Parseia exames usando Claude Haiku com prompt otimizado
    Processa documentos completos com chunking automÃ¡tico
    
    Args:
        extracted_text: Texto extraÃ­do do PDF
        anthropic_client: Cliente Anthropic
        
    Returns:
        Lista de exames estruturados
    """
    # Processar texto completo em chunks se necessÃ¡rio
    max_chunk_size = 12000  # ~3000 tokens
    
    if len(extracted_text) > max_chunk_size:
        print(f'ğŸ“„ Documento longo detectado: {len(extracted_text)} caracteres')
        return _parse_long_document(extracted_text, anthropic_client, max_chunk_size)
    else:
        return _parse_single_chunk(extracted_text, anthropic_client)


def _parse_single_chunk(text: str, anthropic_client) -> List[Dict[str, Any]]:
    """Parseia um Ãºnico chunk de texto"""
    
    # Lista de biomarcadores vÃ¡lidos (top 80 mais comuns)
    valid_biomarkers = """
BIOMARCADORES VÃLIDOS (use nomes padronizados):
- GLICEMIA JEJUM, HbA1c, INSULINA, HOMA IR, PEPTÃDEO C
- CT (Colesterol Total), LDL, HDL, VLDL, TG (TriglicÃ©rides)
- CREATININA, URÃ‰IA, TFG CKD-EPI, ÃCIDO ÃšRICO
- TGO/AST, TGP/ALT, GGT, FA (Fosfatase Alcalina), ALBUMINA
- TSH, T3 LIVRE, T4 LIVRE, T3 TOTAL, T4 TOTAL
- TESTOSTERONA TOTAL, TESTOSTERONA LIVRE, ESTRADIOL, PROGESTERONA
- CORTISOL, DHEA-S, PROLACTINA, LH, FSH
- 25-OH VIT D, VIT B12, ÃCIDO FÃ“LICO, FERRITINA, FERRO
- PCR ULTRA SENSÃVEL, VHS, HOMOCISTEÃNA, FIBRINOGÃŠNIO
- HEMOGLOBINA, HEMATÃ“CRITO, HEMÃCIAS, LEUCÃ“CITOS, PLAQUETAS
- NEUTRÃ“FILOS, LINFÃ“CITOS, MONÃ“CITOS, EOSINÃ“FILOS, BASÃ“FILOS
- VCM, HCM, CHCM, RDW
- PSA TOTAL, PSA LIVRE, CEA, CA 125, CA 19-9
- SÃ“DIO, POTÃSSIO, CÃLCIO, MAGNÃ‰SIO, FÃ“SFORO, CLORO
- PROTEÃNAS TOTAIS, BILIRRUBINA TOTAL, BBD, BBI
"""
    
    prompt = f"""VocÃª Ã© um extrator especializado de laudos laboratoriais brasileiros.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ TAREFA: EXTRAIR VALORES DE TABELAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TABELAS VERTICAIS (90% dos casos brasileiros):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Valor de ReferÃªncia    â”‚ Resultado  â”‚  â† EXTRAIA DESTA COLUNA
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0 - 20 mm/h           â”‚ 38,0 mm/h  â”‚  â†’ value: "38.0", unit: "mm/h"
â”‚ atÃ© 5 mg/L            â”‚ 2,90 mg/L  â”‚  â†’ value: "2.90", unit: "mg/L"
â”‚ 70 - 99 mg/dL         â”‚ 95 mg/dL   â”‚  â†’ value: "95", unit: "mg/dL"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

OPERADORES (valores nÃ£o-detectÃ¡veis):
â”‚ Inferior a 8 UI/mL â”‚  â†’ value: "< 8", unit: "UI/mL"
â”‚ Superior a 1000    â”‚  â†’ value: "> 1000"

TABELAS HORIZONTAIS (10% dos casos):
Glicemia de Jejum: 95 mg/dL (VR: 70-99)
â†’ value: "95", unit: "mg/dL"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ REGRAS CRÃTICAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. **SEMPRE extraia o valor da coluna "Resultado"**
2. **Converta vÃ­rgula â†’ ponto**: "38,0" â†’ "38.0"
3. **Remova unidades do valor**: "95 mg/dL" â†’ value: "95", unit: "mg/dL"
4. **Preserve operadores**: "Inferior a X" â†’ "< X", "Superior a X" â†’ "> X"
5. **Se nÃ£o encontrar valor numÃ©rico, deixe campo vazio (nÃ£o invente)**
6. **Ignore cabeÃ§alhos de tabela** (nÃ£o sÃ£o biomarcadores)
7. **NUNCA extraia nomes de laboratÃ³rios ou cabeÃ§alhos como biomarcadores**

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXPANSÃƒO DE EXAMES COMPOSTOS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- **Hemograma Completo**: Extraia 13+ biomarcadores individuais:
  HemÃ¡cias, Hemoglobina, HematÃ³crito, VCM, HCM, CHCM, RDW,
  LeucÃ³citos, NeutrÃ³filos, LinfÃ³citos, MonÃ³citos, EosinÃ³filos, BasÃ³filos, Plaquetas

- **Lipidograma**: Extraia 5 biomarcadores:
  CT (Colesterol Total), LDL, HDL, VLDL, TG (TriglicÃ©rides)

- **FunÃ§Ã£o Renal**: Creatinina, Ureia, TFG CKD-EPI, Ãcido Ãšrico

- **FunÃ§Ã£o HepÃ¡tica**: TGO/AST, TGP/ALT, GGT, Fosfatase Alcalina, Bilirrubinas, Albumina

{valid_biomarkers}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ FORMATO JSON (SOMENTE ISSO)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[
  {{
    "exam_name": "VHS",
    "value": "38.0",
    "unit": "mm/h",
    "reference_min": "0",
    "reference_max": "20",
    "status": "alto",
    "method": null,
    "observation": null
  }},
  {{
    "exam_name": "FATOR REUMATÃ“IDE",
    "value": "< 8",
    "unit": "UI/mL",
    "reference_min": null,
    "reference_max": "8",
    "status": "normal",
    "method": null,
    "observation": null
  }},
  {{
    "exam_name": "GLICEMIA JEJUM",
    "value": "95",
    "unit": "mg/dL",
    "reference_min": "70",
    "reference_max": "99",
    "status": "normal",
    "method": null,
    "observation": null
  }}
]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“„ LAUDO A PROCESSAR
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{text[:12000]}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… RESPOSTA (SOMENTE JSON, SEM TEXTO)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"""
    
    try:
        message = anthropic_client.messages.create(
            model=CLAUDE_HAIKU_MODEL,
            max_tokens=CLAUDE_MAX_TOKENS,
            temperature=CLAUDE_TEMPERATURE,
            messages=[{"role": "user", "content": prompt}]
        )
        
        response_text = message.content[0].text
        
        # Extrair JSON da resposta
        json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
        if json_match:
            exams = json.loads(json_match.group(0))
            print(f'âœ… Claude Haiku: {len(exams)} biomarcadores extraÃ­dos')
            return exams
        else:
            print('âš ï¸ Claude Haiku: Resposta sem JSON vÃ¡lido')
            return []
        
    except Exception as e:
        print(f'âŒ Claude Haiku falhou: {e}')
        import traceback
        traceback.print_exc()
        return []


def _parse_long_document(text: str, anthropic_client, chunk_size: int) -> List[Dict[str, Any]]:
    """
    Parseia documentos longos dividindo em chunks com overlap
    Evita perder biomarcadores nas bordas dos chunks
    """
    overlap = 1000  # 1000 chars de overlap entre chunks
    chunks = []
    
    # Dividir texto em chunks com overlap
    for i in range(0, len(text), chunk_size - overlap):
        chunk = text[i:i + chunk_size]
        chunks.append(chunk)
    
    print(f'ğŸ“¦ Processando {len(chunks)} chunks com overlap...')
    
    all_exams = []
    seen_exams = set()  # Para deduplicar entre chunks
    
    for idx, chunk in enumerate(chunks):
        print(f'ğŸ”„ Processando chunk {idx + 1}/{len(chunks)}...')
        chunk_exams = _parse_single_chunk(chunk, anthropic_client)
        
        # Adicionar apenas exames Ãºnicos (evitar duplicatas do overlap)
        for exam in chunk_exams:
            exam_key = f"{exam.get('exam_name', '')}-{exam.get('value', '')}"
            if exam_key not in seen_exams:
                all_exams.append(exam)
                seen_exams.add(exam_key)
    
    print(f'âœ… Total de biomarcadores extraÃ­dos de todos os chunks: {len(all_exams)}')
    return all_exams


def clean_reference_values(exames: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Normaliza valores de referÃªncia (min/max)
    
    Args:
        exames: Lista de exames brutos
        
    Returns:
        Lista de exames com referÃªncias normalizadas
    """
    for exam in exames:
        # Garantir que reference_min e reference_max sejam float ou None
        for field in ['reference_min', 'reference_max']:
            value = exam.get(field)
            
            if value is None or value == '':
                exam[field] = None
            elif isinstance(value, str):
                # Limpar string e converter
                clean_value = value.strip().replace(',', '.')
                try:
                    exam[field] = float(clean_value)
                except ValueError:
                    exam[field] = None
            elif isinstance(value, (int, float)):
                exam[field] = float(value)
        
        # Garantir que value seja numÃ©rico quando possÃ­vel
        value = exam.get('value')
        if isinstance(value, str):
            clean_value = value.strip().replace(',', '.')
            # Remover unidades que possam estar grudadas
            clean_value = re.sub(r'[a-zA-Z/%]+$', '', clean_value).strip()
            try:
                exam['value'] = float(clean_value)
            except ValueError:
                pass  # Manter como string se nÃ£o for conversÃ­vel
    
    return exames


def deduplicate_exams(exames: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Remove exames duplicados, mantendo o mais completo
    
    Args:
        exames: Lista de exames (pode ter duplicatas)
        
    Returns:
        Lista dedupilcada
    """
    from difflib import SequenceMatcher
    
    def are_similar(name1: str, name2: str, threshold: float = EXAM_NAME_SIMILARITY_THRESHOLD) -> bool:
        """Verifica se dois nomes de exames sÃ£o similares"""
        n1 = name1.lower().strip()
        n2 = name2.lower().strip()
        return SequenceMatcher(None, n1, n2).ratio() >= threshold
    
    def completeness_score(exam: Dict[str, Any]) -> int:
        """Calcula pontuaÃ§Ã£o de completude de um exame"""
        score = 0
        if exam.get('value') not in [None, '']:
            score += 10
        if exam.get('reference_min') is not None:
            score += 5
        if exam.get('reference_max') is not None:
            score += 5
        if exam.get('unit'):
            score += 3
        if exam.get('status'):
            score += 2
        if exam.get('method'):
            score += 1
        return score
    
    # Agrupar exames similares
    groups = []
    for exam in exames:
        exam_name = exam.get('exam_name', '')
        
        # Tentar adicionar a um grupo existente
        added = False
        for group in groups:
            if are_similar(group[0]['exam_name'], exam_name):
                group.append(exam)
                added = True
                break
        
        # Criar novo grupo se necessÃ¡rio
        if not added:
            groups.append([exam])
    
    # Manter o mais completo de cada grupo
    deduplicated = []
    for group in groups:
        if len(group) == 1:
            deduplicated.append(group[0])
        else:
            # Ordenar por completude e pegar o melhor
            sorted_group = sorted(group, key=completeness_score, reverse=True)
            deduplicated.append(sorted_group[0])
            print(f'ğŸ”„ Deduplicado: {sorted_group[0]["exam_name"]} ({len(group)} versÃµes)')
    
    print(f'âœ… DeduplicaÃ§Ã£o: {len(exames)} -> {len(deduplicated)} exames')
    return deduplicated


def assign_biomarker_ids(exames: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Adiciona IDs Ãºnicos a cada exame
    
    Args:
        exames: Lista de exames
        
    Returns:
        Lista de exames com biomarker_id
    """
    for exam in exames:
        if 'biomarker_id' not in exam:
            exam['biomarker_id'] = str(uuid.uuid4())
    
    return exames
